\chapter{Fundamentação Teórica}
\label{cap:fundamentacao-teorica}

Esta seção apresenta os fundamentos teóricos relacionados às redes
neurais. Na seção 2.1 abordaremos o \textit{Multilayer Perceptron}(MLP), em seguida na seção 2.2 falaremos sobre a \textit{Radial Basis Function}(RBF), logo depois na seção 2.3 sobre \textit{Adaptive Resonance Theory}(ART), depois na seção 2.4 discorreremos sobre a rede \textit{Kohonen} e finalmente na seção 2.5 concluiremos o capítulo.

\section{Redes Neurais}
\label{sec:redes-neurais}



\section{Multilayer Perceptron}
\label{sec:multilayer-perceptron}

A MLP utiliza uma camada intermediária de neurônio entre a camada de entrada e a camada de saída, geralmente este modelo é constituído de múltiplas camadas de neurônios, onde essas camadas são interconectadas às camadas posteriores em direção a camada de saída. 

O perceptron Multicamadas utiliza um processo de treinamento chamado \textit{backpropagation} que é dividido em duas fases, sendo a primeira a propagação adiante, onde o conjunto de amostras de treinamento são inseridas nas entradas da rede e são propagadas camada a camada até a produção da saída respectiva.A segunda fase é chamada de propagação reversa onde os pesos sinápticos e limiares são ajustados durante o processo.
 As aplicações sucessivas dessas fases fazem com que os pesos sinápticos e os limiares sejam ajustados automaticamente em cada iteração, implicando-se gradativa diminuição da soma dos erros produzidos pelas respostas da rede frente aquelas desejadas





\section{Radial Basis Function}
\label{sec:radial-basis-function}

\section{Adaptive Resonance Theory}
\label{sec:adaptive-resonance-theory}


\section{Kohonen}
\label{sec:kohonen}


\section{Conclusão}
\label{sec:conclusão}
